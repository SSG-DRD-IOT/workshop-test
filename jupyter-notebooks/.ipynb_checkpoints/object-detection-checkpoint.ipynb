{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection with OpenVINO™ toolkit \n",
    "\n",
    "This tutorial uses a Single Shot MultiBox Detector (SSD) on a trained mobilenet-ssd* model to walk you through the basic steps of using two key components of the OpenVINO™ toolkit: Model Optimizer and Inference Engine. \n",
    "\n",
    "Model Optimizer is a cross-platform command-line tool that takes pre-trained deep learning models and optimizes them for performance/space using conservative topology transformations. It performs static model analysis and adjusts deep learning models for optimal execution on end-point target devices. \n",
    "\n",
    "Inference is the process of using a trained neural network to interpret data, such as images. This lab feeds a short video of cars, frame-by-frame, to the Inference Engine which subsequently utilizes an optimized trained neural network to detect cars. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Lab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mInitializing operating system environment variables\u001b[0m\n",
      "env: PASSWORD=upsquared\n",
      "\u001b[34;1m\n",
      "Storing OpenVINO directories in environment variables\u001b[0m\n",
      "env: OPENVINO_EXAMPLES=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/\n",
      "env: OPENIVNO_MODEL_OPTIMIZER=/opt/intel/computer_vision_sdk/deployment_tools/model_optimizer\n",
      "env: OPENVINO_OBJECT_DETCTION_EXAMPLE=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/object-detection/\n",
      "\u001b[34;1m\n",
      "Storing workshop lab directories in environment variables\u001b[0m\n",
      "env: WORKSHOP_DIR=/home/upsquared/labs/smart-video-workshop\n"
     ]
    }
   ],
   "source": [
    "# Environment variables that apply to all labs\n",
    "%run 'environment/global.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34;1mInitializing operating system environment variables\u001b[0m\n",
      "env: CAFFE_MODELS=/opt/intel/computer_vision_sdk/deployment_tools/model_downloader/object_detection/common/mobilenet-ssd/caffe/\n",
      "env: LAB=/home/upsquared/labs/smart-video-workshop/object-detection/\n"
     ]
    }
   ],
   "source": [
    "# Environment variables that specific to this lab\n",
    "%run 'environment/setup-image-classification.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Neural Network Model\n",
    "\n",
    "To prepare to run a model on the OpenVINO inference engine the model must be converted to Intermediate Representation (IR), the format used by the OpenVINO Inference Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments\n",
      "\tBatch: \t1\n",
      "\tPrecision of IR: \tFP32\n",
      "\tEnable fusing: \tTrue\n",
      "\tEnable gfusing: \tTrue\n",
      "\tNames of input layers: \tinherited from the model\n",
      "\tPath to the Input Model: \t/opt/intel/computer_vision_sdk/deployment_tools/model_downloader/object_detection/common/mobilenet-ssd/caffe//mobilenet-ssd.caffemodel\n",
      "\tInput shapes: \tinherited from the model\n",
      "\tLog level: \tERROR\n",
      "\tMean values: \t[127,127,127]\n",
      "\tIR output name: \tinherited from the model\n",
      "\tNames of output layers: \tinherited from the model\n",
      "\tPath for generated IR: \t/opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/mobilenet-ssd/FP32\n",
      "\tReverse input channels: \tFalse\n",
      "\tScale factor: \t256.0\n",
      "\tScale values: \t()\n",
      "\tVersion: \t0.3.75.d6bae621\n",
      "\tInput proto file: \tdeduced from the input model\n",
      "\tPath to CustomLayersMapping.xml: \t/opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/extensions/front/caffe/CustomLayersMapping.xml\n",
      "\tPath to a mean file: \t\n",
      "\tOffsets for a mean file: \tNone\n",
      "[ ERROR ]  Failed to create directory /opt/intel/computer_vision_sdk/deployment_tools/model_optimizer/mobilenet-ssd/FP32. Permission denied! For more information please refer to Model Optimizer FAQ, question #22.\n"
     ]
    }
   ],
   "source": [
    "! python3 $OPENIVNO_MODEL_OPTIMIZER/mo_caffe.py \\\n",
    "    --input_model $CAFFE_MODELS/mobilenet-ssd.caffemodel \\\n",
    "    -o $OPENIVNO_MODEL_OPTIMIZER/mobilenet-ssd/FP32 \\\n",
    "    --scale 256 \\\n",
    "    --mean_values [127,127,127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/upsquared/labs/smart-video-workshop/object-detection'\n",
      "g++ -fPIE -O3 -o tutorial1 --std=c++11 main.cpp -I. \\\n",
      "            -I/opt/intel/computer_vision_sdk/opencv/include/ \\\n",
      "            -I/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/include/ \\\n",
      "            -I/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/include/cpp \\\n",
      "            -L/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 -linference_engine -ldl -lpthread -lcpu_extension_avx2 -lcpu_extension_sse4 \\\n",
      "            -L/opt/intel/computer_vision_sdk/opencv/lib -lopencv_core -lopencv_imgcodecs -lopencv_imgproc -lopencv_highgui -lopencv_videoio -lopencv_video -lgflags -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/include -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/samples/ -I./ -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/samples/common/format_reader/ -I/opt/intel/computer_vision_sdk_2018.1.265/opencv/include -I/usr/local/include -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/samples/thirdparty/gflags/include -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/include -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/include/cpp -I/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/samples/extension -L/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/bin/intel64/Release/lib -L/opt/intel/computer_vision_sdk_2018.1.265/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 -L/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib -L/opt/intel/computer_vision_sdk_2018.1.265/opencv/lib -ldl -linference_engine -lopencv_highgui -lopencv_core -lopencv_imgproc -lopencv_videoio -lgflags_nothreads -lopencv_imgcodecs -lopencv_imgcodecs \n",
      "make: Leaving directory '/home/upsquared/labs/smart-video-workshop/object-detection'\n"
     ]
    }
   ],
   "source": [
    "! make --directory=$LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load library '/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so': /opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so: cannot open shared object file: No such file or directory\n",
      "/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/include/details/os/lin_shared_object_loader.h:43\n"
     ]
    }
   ],
   "source": [
    "! $LAB/tutorial1 -i $LAB/object-detection/cars.mp4 -m $LAB/mobilenet-ssd/FP32/mobilenet-ssd.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
